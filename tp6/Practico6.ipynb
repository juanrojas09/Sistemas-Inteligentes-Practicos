{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Métodos ensemble:\n",
        "\n",
        "1. Cargar los datos MNIST y dividirlos en un conjunto de entrenamiento, un conjunto de validación y un conjunto de test (por ejemplo, utilizar 50.000 instancias para entrenamiento, 10.000 para validación y 10.000 para pruebas). Luego, entrenar varios clasificadores, como un clasificador Random Forest, un clasificador Extra-Trees y un clasificador SVM. A continuación, intentar combinarlos en un conjunto que supere a cada clasificador individual en el conjunto de validación, utilizando votación soft o hard. Una vez que haya encontrado uno, probarlo en el conjunto de pruebas. ¿Cuánto mejor se desempeña en comparación con los clasificadores individuales?\n",
        "\n",
        "2. Ejecutar los clasificadores individuales del ejercicio anterior para hacer predicciones en el conjunto de validación y crear un nuevo conjunto de entrenamiento con las predicciones resultantes: cada instancia de entrenamiento es un vector que contiene el conjunto de predicciones de todos los clasificadores para una imagen, y el objetivo es la clase de la imagen. Entrenar un clasificador en este nuevo conjunto de entrenamiento. ¡Felicidades, acaba de entrenar un blender, y junto con los clasificadores forma un conjunto de stacking! Ahora evaluar el conjunto en el conjunto de pruebas. Para cada imagen en el conjunto de pruebas, hacer predicciones con todos los clasificadores, y luego alimentar las predicciones al mezclador para obtener las predicciones del conjunto. ¿Cómo se compara con el clasificador de votación que entrenó anteriormente?\n",
        "\n",
        "3. Realice el ejercicio 1. otra vez utilizando los algoritmo XGBoost, LightGBM y CatBoost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lcRXifnzyOJi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/juan-pablo/.local/lib/python3.8/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'data':        pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              " 0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " ...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              " 69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " \n",
              "        pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
              " 0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " ...        ...  ...       ...       ...       ...       ...       ...   \n",
              " 69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " \n",
              "        pixel780  pixel781  pixel782  pixel783  pixel784  \n",
              " 0           0.0       0.0       0.0       0.0       0.0  \n",
              " 1           0.0       0.0       0.0       0.0       0.0  \n",
              " 2           0.0       0.0       0.0       0.0       0.0  \n",
              " 3           0.0       0.0       0.0       0.0       0.0  \n",
              " 4           0.0       0.0       0.0       0.0       0.0  \n",
              " ...         ...       ...       ...       ...       ...  \n",
              " 69995       0.0       0.0       0.0       0.0       0.0  \n",
              " 69996       0.0       0.0       0.0       0.0       0.0  \n",
              " 69997       0.0       0.0       0.0       0.0       0.0  \n",
              " 69998       0.0       0.0       0.0       0.0       0.0  \n",
              " 69999       0.0       0.0       0.0       0.0       0.0  \n",
              " \n",
              " [70000 rows x 784 columns],\n",
              " 'target': 0        5\n",
              " 1        0\n",
              " 2        4\n",
              " 3        1\n",
              " 4        9\n",
              "         ..\n",
              " 69995    2\n",
              " 69996    3\n",
              " 69997    4\n",
              " 69998    5\n",
              " 69999    6\n",
              " Name: class, Length: 70000, dtype: category\n",
              " Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9'],\n",
              " 'frame':        pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              " 0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " ...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              " 69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " 69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              " \n",
              "        pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              " 0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " ...        ...  ...       ...       ...       ...       ...       ...   \n",
              " 69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " 69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
              " \n",
              "        pixel781  pixel782  pixel783  pixel784  class  \n",
              " 0           0.0       0.0       0.0       0.0      5  \n",
              " 1           0.0       0.0       0.0       0.0      0  \n",
              " 2           0.0       0.0       0.0       0.0      4  \n",
              " 3           0.0       0.0       0.0       0.0      1  \n",
              " 4           0.0       0.0       0.0       0.0      9  \n",
              " ...         ...       ...       ...       ...    ...  \n",
              " 69995       0.0       0.0       0.0       0.0      2  \n",
              " 69996       0.0       0.0       0.0       0.0      3  \n",
              " 69997       0.0       0.0       0.0       0.0      4  \n",
              " 69998       0.0       0.0       0.0       0.0      5  \n",
              " 69999       0.0       0.0       0.0       0.0      6  \n",
              " \n",
              " [70000 rows x 785 columns],\n",
              " 'categories': None,\n",
              " 'feature_names': ['pixel1',\n",
              "  'pixel2',\n",
              "  'pixel3',\n",
              "  'pixel4',\n",
              "  'pixel5',\n",
              "  'pixel6',\n",
              "  'pixel7',\n",
              "  'pixel8',\n",
              "  'pixel9',\n",
              "  'pixel10',\n",
              "  'pixel11',\n",
              "  'pixel12',\n",
              "  'pixel13',\n",
              "  'pixel14',\n",
              "  'pixel15',\n",
              "  'pixel16',\n",
              "  'pixel17',\n",
              "  'pixel18',\n",
              "  'pixel19',\n",
              "  'pixel20',\n",
              "  'pixel21',\n",
              "  'pixel22',\n",
              "  'pixel23',\n",
              "  'pixel24',\n",
              "  'pixel25',\n",
              "  'pixel26',\n",
              "  'pixel27',\n",
              "  'pixel28',\n",
              "  'pixel29',\n",
              "  'pixel30',\n",
              "  'pixel31',\n",
              "  'pixel32',\n",
              "  'pixel33',\n",
              "  'pixel34',\n",
              "  'pixel35',\n",
              "  'pixel36',\n",
              "  'pixel37',\n",
              "  'pixel38',\n",
              "  'pixel39',\n",
              "  'pixel40',\n",
              "  'pixel41',\n",
              "  'pixel42',\n",
              "  'pixel43',\n",
              "  'pixel44',\n",
              "  'pixel45',\n",
              "  'pixel46',\n",
              "  'pixel47',\n",
              "  'pixel48',\n",
              "  'pixel49',\n",
              "  'pixel50',\n",
              "  'pixel51',\n",
              "  'pixel52',\n",
              "  'pixel53',\n",
              "  'pixel54',\n",
              "  'pixel55',\n",
              "  'pixel56',\n",
              "  'pixel57',\n",
              "  'pixel58',\n",
              "  'pixel59',\n",
              "  'pixel60',\n",
              "  'pixel61',\n",
              "  'pixel62',\n",
              "  'pixel63',\n",
              "  'pixel64',\n",
              "  'pixel65',\n",
              "  'pixel66',\n",
              "  'pixel67',\n",
              "  'pixel68',\n",
              "  'pixel69',\n",
              "  'pixel70',\n",
              "  'pixel71',\n",
              "  'pixel72',\n",
              "  'pixel73',\n",
              "  'pixel74',\n",
              "  'pixel75',\n",
              "  'pixel76',\n",
              "  'pixel77',\n",
              "  'pixel78',\n",
              "  'pixel79',\n",
              "  'pixel80',\n",
              "  'pixel81',\n",
              "  'pixel82',\n",
              "  'pixel83',\n",
              "  'pixel84',\n",
              "  'pixel85',\n",
              "  'pixel86',\n",
              "  'pixel87',\n",
              "  'pixel88',\n",
              "  'pixel89',\n",
              "  'pixel90',\n",
              "  'pixel91',\n",
              "  'pixel92',\n",
              "  'pixel93',\n",
              "  'pixel94',\n",
              "  'pixel95',\n",
              "  'pixel96',\n",
              "  'pixel97',\n",
              "  'pixel98',\n",
              "  'pixel99',\n",
              "  'pixel100',\n",
              "  'pixel101',\n",
              "  'pixel102',\n",
              "  'pixel103',\n",
              "  'pixel104',\n",
              "  'pixel105',\n",
              "  'pixel106',\n",
              "  'pixel107',\n",
              "  'pixel108',\n",
              "  'pixel109',\n",
              "  'pixel110',\n",
              "  'pixel111',\n",
              "  'pixel112',\n",
              "  'pixel113',\n",
              "  'pixel114',\n",
              "  'pixel115',\n",
              "  'pixel116',\n",
              "  'pixel117',\n",
              "  'pixel118',\n",
              "  'pixel119',\n",
              "  'pixel120',\n",
              "  'pixel121',\n",
              "  'pixel122',\n",
              "  'pixel123',\n",
              "  'pixel124',\n",
              "  'pixel125',\n",
              "  'pixel126',\n",
              "  'pixel127',\n",
              "  'pixel128',\n",
              "  'pixel129',\n",
              "  'pixel130',\n",
              "  'pixel131',\n",
              "  'pixel132',\n",
              "  'pixel133',\n",
              "  'pixel134',\n",
              "  'pixel135',\n",
              "  'pixel136',\n",
              "  'pixel137',\n",
              "  'pixel138',\n",
              "  'pixel139',\n",
              "  'pixel140',\n",
              "  'pixel141',\n",
              "  'pixel142',\n",
              "  'pixel143',\n",
              "  'pixel144',\n",
              "  'pixel145',\n",
              "  'pixel146',\n",
              "  'pixel147',\n",
              "  'pixel148',\n",
              "  'pixel149',\n",
              "  'pixel150',\n",
              "  'pixel151',\n",
              "  'pixel152',\n",
              "  'pixel153',\n",
              "  'pixel154',\n",
              "  'pixel155',\n",
              "  'pixel156',\n",
              "  'pixel157',\n",
              "  'pixel158',\n",
              "  'pixel159',\n",
              "  'pixel160',\n",
              "  'pixel161',\n",
              "  'pixel162',\n",
              "  'pixel163',\n",
              "  'pixel164',\n",
              "  'pixel165',\n",
              "  'pixel166',\n",
              "  'pixel167',\n",
              "  'pixel168',\n",
              "  'pixel169',\n",
              "  'pixel170',\n",
              "  'pixel171',\n",
              "  'pixel172',\n",
              "  'pixel173',\n",
              "  'pixel174',\n",
              "  'pixel175',\n",
              "  'pixel176',\n",
              "  'pixel177',\n",
              "  'pixel178',\n",
              "  'pixel179',\n",
              "  'pixel180',\n",
              "  'pixel181',\n",
              "  'pixel182',\n",
              "  'pixel183',\n",
              "  'pixel184',\n",
              "  'pixel185',\n",
              "  'pixel186',\n",
              "  'pixel187',\n",
              "  'pixel188',\n",
              "  'pixel189',\n",
              "  'pixel190',\n",
              "  'pixel191',\n",
              "  'pixel192',\n",
              "  'pixel193',\n",
              "  'pixel194',\n",
              "  'pixel195',\n",
              "  'pixel196',\n",
              "  'pixel197',\n",
              "  'pixel198',\n",
              "  'pixel199',\n",
              "  'pixel200',\n",
              "  'pixel201',\n",
              "  'pixel202',\n",
              "  'pixel203',\n",
              "  'pixel204',\n",
              "  'pixel205',\n",
              "  'pixel206',\n",
              "  'pixel207',\n",
              "  'pixel208',\n",
              "  'pixel209',\n",
              "  'pixel210',\n",
              "  'pixel211',\n",
              "  'pixel212',\n",
              "  'pixel213',\n",
              "  'pixel214',\n",
              "  'pixel215',\n",
              "  'pixel216',\n",
              "  'pixel217',\n",
              "  'pixel218',\n",
              "  'pixel219',\n",
              "  'pixel220',\n",
              "  'pixel221',\n",
              "  'pixel222',\n",
              "  'pixel223',\n",
              "  'pixel224',\n",
              "  'pixel225',\n",
              "  'pixel226',\n",
              "  'pixel227',\n",
              "  'pixel228',\n",
              "  'pixel229',\n",
              "  'pixel230',\n",
              "  'pixel231',\n",
              "  'pixel232',\n",
              "  'pixel233',\n",
              "  'pixel234',\n",
              "  'pixel235',\n",
              "  'pixel236',\n",
              "  'pixel237',\n",
              "  'pixel238',\n",
              "  'pixel239',\n",
              "  'pixel240',\n",
              "  'pixel241',\n",
              "  'pixel242',\n",
              "  'pixel243',\n",
              "  'pixel244',\n",
              "  'pixel245',\n",
              "  'pixel246',\n",
              "  'pixel247',\n",
              "  'pixel248',\n",
              "  'pixel249',\n",
              "  'pixel250',\n",
              "  'pixel251',\n",
              "  'pixel252',\n",
              "  'pixel253',\n",
              "  'pixel254',\n",
              "  'pixel255',\n",
              "  'pixel256',\n",
              "  'pixel257',\n",
              "  'pixel258',\n",
              "  'pixel259',\n",
              "  'pixel260',\n",
              "  'pixel261',\n",
              "  'pixel262',\n",
              "  'pixel263',\n",
              "  'pixel264',\n",
              "  'pixel265',\n",
              "  'pixel266',\n",
              "  'pixel267',\n",
              "  'pixel268',\n",
              "  'pixel269',\n",
              "  'pixel270',\n",
              "  'pixel271',\n",
              "  'pixel272',\n",
              "  'pixel273',\n",
              "  'pixel274',\n",
              "  'pixel275',\n",
              "  'pixel276',\n",
              "  'pixel277',\n",
              "  'pixel278',\n",
              "  'pixel279',\n",
              "  'pixel280',\n",
              "  'pixel281',\n",
              "  'pixel282',\n",
              "  'pixel283',\n",
              "  'pixel284',\n",
              "  'pixel285',\n",
              "  'pixel286',\n",
              "  'pixel287',\n",
              "  'pixel288',\n",
              "  'pixel289',\n",
              "  'pixel290',\n",
              "  'pixel291',\n",
              "  'pixel292',\n",
              "  'pixel293',\n",
              "  'pixel294',\n",
              "  'pixel295',\n",
              "  'pixel296',\n",
              "  'pixel297',\n",
              "  'pixel298',\n",
              "  'pixel299',\n",
              "  'pixel300',\n",
              "  'pixel301',\n",
              "  'pixel302',\n",
              "  'pixel303',\n",
              "  'pixel304',\n",
              "  'pixel305',\n",
              "  'pixel306',\n",
              "  'pixel307',\n",
              "  'pixel308',\n",
              "  'pixel309',\n",
              "  'pixel310',\n",
              "  'pixel311',\n",
              "  'pixel312',\n",
              "  'pixel313',\n",
              "  'pixel314',\n",
              "  'pixel315',\n",
              "  'pixel316',\n",
              "  'pixel317',\n",
              "  'pixel318',\n",
              "  'pixel319',\n",
              "  'pixel320',\n",
              "  'pixel321',\n",
              "  'pixel322',\n",
              "  'pixel323',\n",
              "  'pixel324',\n",
              "  'pixel325',\n",
              "  'pixel326',\n",
              "  'pixel327',\n",
              "  'pixel328',\n",
              "  'pixel329',\n",
              "  'pixel330',\n",
              "  'pixel331',\n",
              "  'pixel332',\n",
              "  'pixel333',\n",
              "  'pixel334',\n",
              "  'pixel335',\n",
              "  'pixel336',\n",
              "  'pixel337',\n",
              "  'pixel338',\n",
              "  'pixel339',\n",
              "  'pixel340',\n",
              "  'pixel341',\n",
              "  'pixel342',\n",
              "  'pixel343',\n",
              "  'pixel344',\n",
              "  'pixel345',\n",
              "  'pixel346',\n",
              "  'pixel347',\n",
              "  'pixel348',\n",
              "  'pixel349',\n",
              "  'pixel350',\n",
              "  'pixel351',\n",
              "  'pixel352',\n",
              "  'pixel353',\n",
              "  'pixel354',\n",
              "  'pixel355',\n",
              "  'pixel356',\n",
              "  'pixel357',\n",
              "  'pixel358',\n",
              "  'pixel359',\n",
              "  'pixel360',\n",
              "  'pixel361',\n",
              "  'pixel362',\n",
              "  'pixel363',\n",
              "  'pixel364',\n",
              "  'pixel365',\n",
              "  'pixel366',\n",
              "  'pixel367',\n",
              "  'pixel368',\n",
              "  'pixel369',\n",
              "  'pixel370',\n",
              "  'pixel371',\n",
              "  'pixel372',\n",
              "  'pixel373',\n",
              "  'pixel374',\n",
              "  'pixel375',\n",
              "  'pixel376',\n",
              "  'pixel377',\n",
              "  'pixel378',\n",
              "  'pixel379',\n",
              "  'pixel380',\n",
              "  'pixel381',\n",
              "  'pixel382',\n",
              "  'pixel383',\n",
              "  'pixel384',\n",
              "  'pixel385',\n",
              "  'pixel386',\n",
              "  'pixel387',\n",
              "  'pixel388',\n",
              "  'pixel389',\n",
              "  'pixel390',\n",
              "  'pixel391',\n",
              "  'pixel392',\n",
              "  'pixel393',\n",
              "  'pixel394',\n",
              "  'pixel395',\n",
              "  'pixel396',\n",
              "  'pixel397',\n",
              "  'pixel398',\n",
              "  'pixel399',\n",
              "  'pixel400',\n",
              "  'pixel401',\n",
              "  'pixel402',\n",
              "  'pixel403',\n",
              "  'pixel404',\n",
              "  'pixel405',\n",
              "  'pixel406',\n",
              "  'pixel407',\n",
              "  'pixel408',\n",
              "  'pixel409',\n",
              "  'pixel410',\n",
              "  'pixel411',\n",
              "  'pixel412',\n",
              "  'pixel413',\n",
              "  'pixel414',\n",
              "  'pixel415',\n",
              "  'pixel416',\n",
              "  'pixel417',\n",
              "  'pixel418',\n",
              "  'pixel419',\n",
              "  'pixel420',\n",
              "  'pixel421',\n",
              "  'pixel422',\n",
              "  'pixel423',\n",
              "  'pixel424',\n",
              "  'pixel425',\n",
              "  'pixel426',\n",
              "  'pixel427',\n",
              "  'pixel428',\n",
              "  'pixel429',\n",
              "  'pixel430',\n",
              "  'pixel431',\n",
              "  'pixel432',\n",
              "  'pixel433',\n",
              "  'pixel434',\n",
              "  'pixel435',\n",
              "  'pixel436',\n",
              "  'pixel437',\n",
              "  'pixel438',\n",
              "  'pixel439',\n",
              "  'pixel440',\n",
              "  'pixel441',\n",
              "  'pixel442',\n",
              "  'pixel443',\n",
              "  'pixel444',\n",
              "  'pixel445',\n",
              "  'pixel446',\n",
              "  'pixel447',\n",
              "  'pixel448',\n",
              "  'pixel449',\n",
              "  'pixel450',\n",
              "  'pixel451',\n",
              "  'pixel452',\n",
              "  'pixel453',\n",
              "  'pixel454',\n",
              "  'pixel455',\n",
              "  'pixel456',\n",
              "  'pixel457',\n",
              "  'pixel458',\n",
              "  'pixel459',\n",
              "  'pixel460',\n",
              "  'pixel461',\n",
              "  'pixel462',\n",
              "  'pixel463',\n",
              "  'pixel464',\n",
              "  'pixel465',\n",
              "  'pixel466',\n",
              "  'pixel467',\n",
              "  'pixel468',\n",
              "  'pixel469',\n",
              "  'pixel470',\n",
              "  'pixel471',\n",
              "  'pixel472',\n",
              "  'pixel473',\n",
              "  'pixel474',\n",
              "  'pixel475',\n",
              "  'pixel476',\n",
              "  'pixel477',\n",
              "  'pixel478',\n",
              "  'pixel479',\n",
              "  'pixel480',\n",
              "  'pixel481',\n",
              "  'pixel482',\n",
              "  'pixel483',\n",
              "  'pixel484',\n",
              "  'pixel485',\n",
              "  'pixel486',\n",
              "  'pixel487',\n",
              "  'pixel488',\n",
              "  'pixel489',\n",
              "  'pixel490',\n",
              "  'pixel491',\n",
              "  'pixel492',\n",
              "  'pixel493',\n",
              "  'pixel494',\n",
              "  'pixel495',\n",
              "  'pixel496',\n",
              "  'pixel497',\n",
              "  'pixel498',\n",
              "  'pixel499',\n",
              "  'pixel500',\n",
              "  'pixel501',\n",
              "  'pixel502',\n",
              "  'pixel503',\n",
              "  'pixel504',\n",
              "  'pixel505',\n",
              "  'pixel506',\n",
              "  'pixel507',\n",
              "  'pixel508',\n",
              "  'pixel509',\n",
              "  'pixel510',\n",
              "  'pixel511',\n",
              "  'pixel512',\n",
              "  'pixel513',\n",
              "  'pixel514',\n",
              "  'pixel515',\n",
              "  'pixel516',\n",
              "  'pixel517',\n",
              "  'pixel518',\n",
              "  'pixel519',\n",
              "  'pixel520',\n",
              "  'pixel521',\n",
              "  'pixel522',\n",
              "  'pixel523',\n",
              "  'pixel524',\n",
              "  'pixel525',\n",
              "  'pixel526',\n",
              "  'pixel527',\n",
              "  'pixel528',\n",
              "  'pixel529',\n",
              "  'pixel530',\n",
              "  'pixel531',\n",
              "  'pixel532',\n",
              "  'pixel533',\n",
              "  'pixel534',\n",
              "  'pixel535',\n",
              "  'pixel536',\n",
              "  'pixel537',\n",
              "  'pixel538',\n",
              "  'pixel539',\n",
              "  'pixel540',\n",
              "  'pixel541',\n",
              "  'pixel542',\n",
              "  'pixel543',\n",
              "  'pixel544',\n",
              "  'pixel545',\n",
              "  'pixel546',\n",
              "  'pixel547',\n",
              "  'pixel548',\n",
              "  'pixel549',\n",
              "  'pixel550',\n",
              "  'pixel551',\n",
              "  'pixel552',\n",
              "  'pixel553',\n",
              "  'pixel554',\n",
              "  'pixel555',\n",
              "  'pixel556',\n",
              "  'pixel557',\n",
              "  'pixel558',\n",
              "  'pixel559',\n",
              "  'pixel560',\n",
              "  'pixel561',\n",
              "  'pixel562',\n",
              "  'pixel563',\n",
              "  'pixel564',\n",
              "  'pixel565',\n",
              "  'pixel566',\n",
              "  'pixel567',\n",
              "  'pixel568',\n",
              "  'pixel569',\n",
              "  'pixel570',\n",
              "  'pixel571',\n",
              "  'pixel572',\n",
              "  'pixel573',\n",
              "  'pixel574',\n",
              "  'pixel575',\n",
              "  'pixel576',\n",
              "  'pixel577',\n",
              "  'pixel578',\n",
              "  'pixel579',\n",
              "  'pixel580',\n",
              "  'pixel581',\n",
              "  'pixel582',\n",
              "  'pixel583',\n",
              "  'pixel584',\n",
              "  'pixel585',\n",
              "  'pixel586',\n",
              "  'pixel587',\n",
              "  'pixel588',\n",
              "  'pixel589',\n",
              "  'pixel590',\n",
              "  'pixel591',\n",
              "  'pixel592',\n",
              "  'pixel593',\n",
              "  'pixel594',\n",
              "  'pixel595',\n",
              "  'pixel596',\n",
              "  'pixel597',\n",
              "  'pixel598',\n",
              "  'pixel599',\n",
              "  'pixel600',\n",
              "  'pixel601',\n",
              "  'pixel602',\n",
              "  'pixel603',\n",
              "  'pixel604',\n",
              "  'pixel605',\n",
              "  'pixel606',\n",
              "  'pixel607',\n",
              "  'pixel608',\n",
              "  'pixel609',\n",
              "  'pixel610',\n",
              "  'pixel611',\n",
              "  'pixel612',\n",
              "  'pixel613',\n",
              "  'pixel614',\n",
              "  'pixel615',\n",
              "  'pixel616',\n",
              "  'pixel617',\n",
              "  'pixel618',\n",
              "  'pixel619',\n",
              "  'pixel620',\n",
              "  'pixel621',\n",
              "  'pixel622',\n",
              "  'pixel623',\n",
              "  'pixel624',\n",
              "  'pixel625',\n",
              "  'pixel626',\n",
              "  'pixel627',\n",
              "  'pixel628',\n",
              "  'pixel629',\n",
              "  'pixel630',\n",
              "  'pixel631',\n",
              "  'pixel632',\n",
              "  'pixel633',\n",
              "  'pixel634',\n",
              "  'pixel635',\n",
              "  'pixel636',\n",
              "  'pixel637',\n",
              "  'pixel638',\n",
              "  'pixel639',\n",
              "  'pixel640',\n",
              "  'pixel641',\n",
              "  'pixel642',\n",
              "  'pixel643',\n",
              "  'pixel644',\n",
              "  'pixel645',\n",
              "  'pixel646',\n",
              "  'pixel647',\n",
              "  'pixel648',\n",
              "  'pixel649',\n",
              "  'pixel650',\n",
              "  'pixel651',\n",
              "  'pixel652',\n",
              "  'pixel653',\n",
              "  'pixel654',\n",
              "  'pixel655',\n",
              "  'pixel656',\n",
              "  'pixel657',\n",
              "  'pixel658',\n",
              "  'pixel659',\n",
              "  'pixel660',\n",
              "  'pixel661',\n",
              "  'pixel662',\n",
              "  'pixel663',\n",
              "  'pixel664',\n",
              "  'pixel665',\n",
              "  'pixel666',\n",
              "  'pixel667',\n",
              "  'pixel668',\n",
              "  'pixel669',\n",
              "  'pixel670',\n",
              "  'pixel671',\n",
              "  'pixel672',\n",
              "  'pixel673',\n",
              "  'pixel674',\n",
              "  'pixel675',\n",
              "  'pixel676',\n",
              "  'pixel677',\n",
              "  'pixel678',\n",
              "  'pixel679',\n",
              "  'pixel680',\n",
              "  'pixel681',\n",
              "  'pixel682',\n",
              "  'pixel683',\n",
              "  'pixel684',\n",
              "  'pixel685',\n",
              "  'pixel686',\n",
              "  'pixel687',\n",
              "  'pixel688',\n",
              "  'pixel689',\n",
              "  'pixel690',\n",
              "  'pixel691',\n",
              "  'pixel692',\n",
              "  'pixel693',\n",
              "  'pixel694',\n",
              "  'pixel695',\n",
              "  'pixel696',\n",
              "  'pixel697',\n",
              "  'pixel698',\n",
              "  'pixel699',\n",
              "  'pixel700',\n",
              "  'pixel701',\n",
              "  'pixel702',\n",
              "  'pixel703',\n",
              "  'pixel704',\n",
              "  'pixel705',\n",
              "  'pixel706',\n",
              "  'pixel707',\n",
              "  'pixel708',\n",
              "  'pixel709',\n",
              "  'pixel710',\n",
              "  'pixel711',\n",
              "  'pixel712',\n",
              "  'pixel713',\n",
              "  'pixel714',\n",
              "  'pixel715',\n",
              "  'pixel716',\n",
              "  'pixel717',\n",
              "  'pixel718',\n",
              "  'pixel719',\n",
              "  'pixel720',\n",
              "  'pixel721',\n",
              "  'pixel722',\n",
              "  'pixel723',\n",
              "  'pixel724',\n",
              "  'pixel725',\n",
              "  'pixel726',\n",
              "  'pixel727',\n",
              "  'pixel728',\n",
              "  'pixel729',\n",
              "  'pixel730',\n",
              "  'pixel731',\n",
              "  'pixel732',\n",
              "  'pixel733',\n",
              "  'pixel734',\n",
              "  'pixel735',\n",
              "  'pixel736',\n",
              "  'pixel737',\n",
              "  'pixel738',\n",
              "  'pixel739',\n",
              "  'pixel740',\n",
              "  'pixel741',\n",
              "  'pixel742',\n",
              "  'pixel743',\n",
              "  'pixel744',\n",
              "  'pixel745',\n",
              "  'pixel746',\n",
              "  'pixel747',\n",
              "  'pixel748',\n",
              "  'pixel749',\n",
              "  'pixel750',\n",
              "  'pixel751',\n",
              "  'pixel752',\n",
              "  'pixel753',\n",
              "  'pixel754',\n",
              "  'pixel755',\n",
              "  'pixel756',\n",
              "  'pixel757',\n",
              "  'pixel758',\n",
              "  'pixel759',\n",
              "  'pixel760',\n",
              "  'pixel761',\n",
              "  'pixel762',\n",
              "  'pixel763',\n",
              "  'pixel764',\n",
              "  'pixel765',\n",
              "  'pixel766',\n",
              "  'pixel767',\n",
              "  'pixel768',\n",
              "  'pixel769',\n",
              "  'pixel770',\n",
              "  'pixel771',\n",
              "  'pixel772',\n",
              "  'pixel773',\n",
              "  'pixel774',\n",
              "  'pixel775',\n",
              "  'pixel776',\n",
              "  'pixel777',\n",
              "  'pixel778',\n",
              "  'pixel779',\n",
              "  'pixel780',\n",
              "  'pixel781',\n",
              "  'pixel782',\n",
              "  'pixel783',\n",
              "  'pixel784'],\n",
              " 'target_names': ['class'],\n",
              " 'DESCR': \"**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \\n**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \\n**Please cite**:  \\n\\nThe MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \\n\\nIt is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \\n\\nWith some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \\n\\nThe MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\\n\\nDownloaded from openml.org.\",\n",
              " 'details': {'id': '554',\n",
              "  'name': 'mnist_784',\n",
              "  'version': '1',\n",
              "  'description_version': '1',\n",
              "  'format': 'ARFF',\n",
              "  'creator': ['Yann LeCun', 'Corinna Cortes', 'Christopher J.C. Burges'],\n",
              "  'upload_date': '2014-09-29T03:28:38',\n",
              "  'language': 'English',\n",
              "  'licence': 'Public',\n",
              "  'url': 'https://api.openml.org/data/v1/download/52667/mnist_784.arff',\n",
              "  'parquet_url': 'http://openml1.win.tue.nl/dataset554/dataset_554.pq',\n",
              "  'file_id': '52667',\n",
              "  'default_target_attribute': 'class',\n",
              "  'tag': ['AzurePilot',\n",
              "   'OpenML-CC18',\n",
              "   'OpenML100',\n",
              "   'study_1',\n",
              "   'study_123',\n",
              "   'study_41',\n",
              "   'study_99',\n",
              "   'vision'],\n",
              "  'visibility': 'public',\n",
              "  'minio_url': 'http://openml1.win.tue.nl/dataset554/dataset_554.pq',\n",
              "  'status': 'active',\n",
              "  'processing_date': '2020-11-20 20:12:09',\n",
              "  'md5_checksum': '0298d579eb1b86163de7723944c7e495'},\n",
              " 'url': 'https://www.openml.org/d/554'}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#importar datos mnist\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "display(mnist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#dividirlos en un conjunto de entrenamiento, un conjunto de validación y un conjunto de test (por ejemplo, utilizar 50.000 instancias para entrenamiento, 10.000 para validación y 10.000 para pruebas)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Divido en caracteristicas y las etiquetas\n",
        "X = mnist[\"data\"].astype('float32')\n",
        "y = mnist[\"target\"].astype('int32')\n",
        "\n",
        "\n",
        "# Dividir los datos en un conjunto de entrenamiento, un conjunto de validación y un conjunto de prueba\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=10000, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=10000, random_state=42)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este ejemplo, estamos utilizando el mismo número de árboles para los clasificadores Random Forest y Extra-Trees (100) y una semilla aleatoria (random_state=42). Para el clasificador SVM, estamos utilizando un kernel radial y una constante de regularización C de 0.1. Además, estamos escalando los datos utilizando un objeto StandardScaler de Scikit-Learn para asegurarnos de que las características tengan la misma escala.\n",
        "\n",
        "Recuerda que estos son solo ejemplos y que puedes ajustar los parámetros de cada clasificador para obtener mejores resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Desempeño del clasificador Random Forest en el conjunto de validación: 0.9692\n"
          ]
        }
      ],
      "source": [
        "#Entreno el model ocon random forest\n",
        "from sklearn.discriminant_analysis import StandardScaler\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "\n",
        " #Evaluar el desempeño del clasificador en el conjunto de validación\n",
        "val_score_rf = rnd_clf.score(X_val, y_val)\n",
        "print(\"Desempeño del clasificador Random Forest en el conjunto de validación:\", val_score_rf)\n",
        "    \n",
        "    # Entrenar un clasificador Extra-Trees\n",
        "et_clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "et_clf.fit(X_train, y_train)\n",
        "\n",
        "# Escalar los datos para entrenar un clasificador SVM\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "\n",
        "# Entrenar un clasificador SVM\n",
        "svm_clf = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"svm\", SVC(kernel=\"rbf\", C=0.1, gamma=0.1, random_state=42))\n",
        "])\n",
        "svm_clf.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Ecombinar los clasificadores mediante votación soft o hard:\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Combinar los clasificadores mediante votación soft\n",
        "voting_clf_soft = VotingClassifier(\n",
        "    estimators=[('rf', rnd_clf), ('et', et_clf), ('svm', svm_clf)],\n",
        "    voting='soft'\n",
        ")\n",
        "voting_clf_soft.fit(X_train, y_train)\n",
        "\n",
        "# Evaluar el desempeño del clasificador combinado en el conjunto de validación\n",
        "val_score_voting_soft = voting_clf_soft.score(X_val, y_val)\n",
        "print(\"Desempeño del clasificador combinado (votación soft) en el conjunto de validación:\", val_score_voting_soft)\n",
        "\n",
        "# Combinar los clasificadores mediante votación hard\n",
        "voting_clf_hard = VotingClassifier(\n",
        "    estimators=[('rf', rnd_clf), ('et', et_clf), ('svm', svm_clf)],\n",
        "    voting='hard'\n",
        ")\n",
        "voting_clf_hard.fit(X_train, y_train)\n",
        "\n",
        "# Evaluar el desempeño del clasificador combinado en el conjunto de validación\n",
        "val_score_voting_hard = voting_clf_hard.score(X_val, y_val)\n",
        "print(\"Desempeño del clasificador combinado (votación hard) en el conjunto de validación:\", val_score_voting_hard)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En este ejemplo, estamos evaluando el desempeño del clasificador combinado en el conjunto de pruebas utilizando el método score(). Además, estamos evaluando el desempeño de los clasificadores individuales en el mismo conjunto de pruebas para poder compararlos.\n",
        "\n",
        "Recuerda que el desempeño del clasificador combinado puede variar dependiendo de los clasificadores individuales y los parámetros utilizados. En general, se espera que el clasificador combinado tenga un mejor desempeño que los clasificadores individuales debido a que se están utilizando varias perspectivas diferentes para realizar la clasificación. Sin embargo, esto no siempre es cierto y es importante evaluar el desempeño del clasificador combinado en un conjunto de pruebas independiente para asegurarse de que sea realmente mejor que los clasificadores individuales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluar el desempeño del clasificador combinado en el conjunto de pruebas\n",
        "test_score_voting_soft = voting_clf_soft.score(X_test, y_test)\n",
        "print(\"Desempeño del clasificador combinado (votación soft) en el conjunto de pruebas:\", test_score_voting_soft)\n",
        "\n",
        "test_score_voting_hard = voting_clf_hard.score(X_test, y_test)\n",
        "print(\"Desempeño del clasificador combinado (votación hard) en el conjunto de pruebas:\", test_score_voting_hard)\n",
        "\n",
        "# Evaluar el desempeño de los clasificadores individuales en el conjunto de pruebas\n",
        "test_score_rf = et_clf.score(X_test, y_test)\n",
        "print(\"Desempeño del clasificador Random Forest en el conjunto de pruebas:\", test_score_rf)\n",
        "\n",
        "test_score_et = et_clf.score(X_test, y_test)\n",
        "print(\"Desempeño del clasificador Extra-Trees en el conjunto de pruebas:\", test_score_et)\n",
        "\n",
        "test_score_svm = svm_clf.score(X_test, y_test)\n",
        "print(\"Desempeño del clasificador SVM en el conjunto de pruebas:\", test_score_svm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#2 hacer predicciones en el conjunto de validación con los clasificadores individuales y crear un nuevo conjunto de entrenamiento con las predicciones resultantes:\n",
        "\n",
        "# Hacer predicciones en el conjunto de validación con los clasificadores individuales\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "y_val_pred_rf = rnd_clf.predict(X_val)\n",
        "y_val_pred_et = et_clf.predict(X_val)\n",
        "y_val_pred_svm = svm_clf.predict(X_val)\n",
        "\n",
        "# Crear un nuevo conjunto de entrenamiento con las predicciones resultantes\n",
        "X_train_new = np.c_[y_val_pred_rf, y_val_pred_et, y_val_pred_svm]\n",
        "y_train_new = y_val\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez que hemos creado el nuevo conjunto de entrenamiento con las predicciones de los clasificadores individuales para cada imagen del conjunto de validación, podemos entrenar el blender en este nuevo conjunto de entrenamiento utilizando Scikit-Learn. Luego, podemos evaluar el desempeño del conjunto de stacking en el conjunto de pruebas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Entrenar el blender en el nuevo conjunto de entrenamiento\n",
        "blender = LogisticRegression(random_state=42)\n",
        "blender.fit(X_train_new, y_train_new)\n",
        "\n",
        "# Hacer predicciones en el conjunto de pruebas con los clasificadores individuales\n",
        "y_test_pred_rf = rnd_clf.predict(X_test)\n",
        "y_test_pred_et = et_clf.predict(X_test)\n",
        "y_test_pred_svm = svm_clf.predict(X_test)\n",
        "\n",
        "# Crear un nuevo conjunto de pruebas con las predicciones resultantes\n",
        "X_test_new = np.c_[y_test_pred_rf, y_test_pred_et, y_test_pred_svm]\n",
        "\n",
        "# Hacer predicciones en el conjunto de pruebas con el blender\n",
        "y_test_pred_blend = blender.predict(X_test_new)\n",
        "\n",
        "# Evaluar el desempeño del conjunto de stacking en el conjunto de pruebas\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test_score_blend = accuracy_score(y_test, y_test_pred_blend)\n",
        "print(\"Desempeño del conjunto de stacking en el conjunto de pruebas:\", test_score_blend)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez que hemos entrenado el blender en el nuevo conjunto de entrenamiento y hemos hecho predicciones en el conjunto de pruebas con los clasificadores individuales, podemos hacer predicciones en el conjunto de pruebas con el blender y evaluar el desempeño del conjunto de stacking en el conjunto de pruebas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hacer predicciones en el conjunto de pruebas con el blender\n",
        "y_test_pred_blend = blender.predict(X_test_new)\n",
        "\n",
        "# Evaluar el desempeño del conjunto de stacking en el conjunto de pruebas\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test_score_blend = accuracy_score(y_test, y_test_pred_blend)\n",
        "print(\"Desempeño del conjunto de stacking en el conjunto de pruebas:\", test_score_blend)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para comparar el desempeño del conjunto de stacking con el clasificador de votación que entrenó anteriormente, primero debemos hacer predicciones en el conjunto de pruebas con todos los clasificadores, y luego combinar estas predicciones utilizando el blender entrenado anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hacer predicciones en el conjunto de pruebas con los clasificadores individuales\n",
        "y_test_pred_rf = rnd_clf.predict(X_test)\n",
        "y_test_pred_et = et_clf.predict(X_test)\n",
        "y_test_pred_svm = svm_clf.predict(X_test)\n",
        "\n",
        "# Crear un nuevo conjunto de pruebas con las predicciones resultantes\n",
        "X_test_new = np.c_[y_test_pred_rf, y_test_pred_et, y_test_pred_svm]\n",
        "\n",
        "# Hacer predicciones en el conjunto de pruebas con el blender\n",
        "y_test_pred_blend = blender.predict(X_test_new)\n",
        "\n",
        "# Evaluar el desempeño del conjunto de stacking en el conjunto de pruebas\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test_score_blend = accuracy_score(y_test, y_test_pred_blend)\n",
        "print(\"Desempeño del conjunto de stacking en el conjunto de pruebas:\", test_score_blend)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ejercicio 1 utilizando los algoritmos XGBoost, LightGBM y CatBoost:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importar los algoritmos XGBoost, LightGBM y CatBoost\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "\n",
        "# Cargar los datos MNIST\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784')\n",
        "\n",
        "# Dividir los datos en un conjunto de entrenamiento, un conjunto de validación y un conjunto de pruebas\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(mnist.data, mnist.target, test_size=10000, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=10000, random_state=42)\n",
        "\n",
        "# Entrenar un clasificador XGBoost\n",
        "xgb_clf = xgb.XGBClassifier(n_jobs=-1, random_state=42)\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Entrenar un clasificador LightGBM\n",
        "lgb_clf = lgb.LGBMClassifier(n_jobs=-1, random_state=42)\n",
        "lgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Entrenar un clasificador CatBoost\n",
        "cb_clf = cb.CatBoostClassifier(verbose=0, random_state=42)\n",
        "cb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Hacer predicciones en el conjunto de validación con los clasificadores individuales\n",
        "y_val_pred_xgb = xgb_clf.predict(X_val)\n",
        "y_val_pred_lgb = lgb_clf.predict(X_val)\n",
        "y_val_pred_cb = cb_clf.predict(X_val)\n",
        "\n",
        "# Calcular la precisión de los clasificadores individuales en el conjunto de validación\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "val_score_xgb = accuracy_score(y_val, y_val_pred_xgb)\n",
        "val_score_lgb = accuracy_score(y_val, y_val_pred_lgb)\n",
        "val_score_cb = accuracy_score(y_val, y_val_pred_cb)\n",
        "\n",
        "print(\"Precisión del clasificador XGBoost en el conjunto de validación:\", val_score_xgb)\n",
        "print(\"Precisión del clasificador LightGBM en el conjunto de validación:\", val_score_lgb)\n",
        "print(\"Precisión del clasificador CatBoost en el conjunto de validación:\", val_score_cb)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ombinar los clasificadores XGBoost, LightGBM y CatBoost en un conjunto que supere a cada clasificador individual en el conjunto de validación, podemos utilizar la votación soft o hard.\n",
        "\n",
        "La votación soft promedia las probabilidades de clasificación de cada clasificador para cada instancia y selecciona la clase con la probabilidad media más alta como la predicción final. Por otro lado, la votación hard selecciona la clase más votada por la mayoría de los clasificadores para cada instancia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Crear una instancia de votación soft\n",
        "voting_clf_soft = VotingClassifier(estimators=[('xgb', xgb_clf), ('lgb', lgb_clf), ('cb', cb_clf)], voting='soft')\n",
        "\n",
        "# Entrenar la votación soft en el conjunto de entrenamiento y validación\n",
        "voting_clf_soft.fit(X_train_val, y_train_val)\n",
        "\n",
        "# Hacer predicciones en el conjunto de pruebas con la votación soft\n",
        "y_test_pred_soft = voting_clf_soft.predict(X_test)\n",
        "\n",
        "# Evaluar el desempeño de la votación soft en el conjunto de pruebas\n",
        "test_score_soft = accuracy_score(y_test, y_test_pred_soft)\n",
        "\n",
        "print(\"Desempeño de la votación soft en el conjunto de pruebas:\", test_score_soft)\n",
        "\n",
        "\n",
        "# Crear una instancia de votación hard\n",
        "voting_clf_hard = VotingClassifier(estimators=[('xgb', xgb_clf), ('lgb', lgb_clf), ('cb', cb_clf)], voting='hard')\n",
        "\n",
        "# Entrenar la votación hard en el conjunto de entrenamiento y validación\n",
        "voting_clf_hard.fit(X_train_val, y_train_val)\n",
        "\n",
        "# Hacer predicciones en el conjunto de pruebas con la votación hard\n",
        "y_test_pred_hard = voting_clf_hard.predict(X_test)\n",
        "\n",
        "# Evaluar el desempeño de la votación hard en el conjunto de pruebas\n",
        "test_score_hard = accuracy_score(y_test, y_test_pred_hard)\n",
        "\n",
        "print(\"Desempeño de la votación hard en el conjunto de pruebas:\", test_score_hard)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Reducción dimensional\n",
        "\n",
        "1. Cargue el conjunto de datos MNIST (introducido en el capítulo 3) y divídalo en un conjunto de entrenamiento y un conjunto de pruebas (tome las primeras 60,000 instancias para entrenamiento y las 10,000 restantes para test). Entrene un clasificador Random Forest en el conjunto de datos y tome el tiempo que tarda, luego evalúe el modelo resultante en el conjunto de test. A continuación, use PCA para reducir la dimensionalidad del conjunto de datos, con una relación de varianza explicada del 95%. Entrenar un nuevo clasificador Random Forest en el conjunto de datos reducido y ver cuánto tiempo tarda. ¿Fue el entrenamiento mucho más rápido? A continuación, evalúe el clasificador en el conjunto de pruebas. ¿Cómo se compara con el clasificador anterior?\n",
        "\n",
        "2. Use t-SNE para reducir el conjunto de datos MNIST a dos dimensiones y grafique el resultado usando Matplotlib. Puede usar un gráfico de dispersión utilizando 10 colores diferentes para representar la clase objetivo de cada imagen. Alternativamente, puede reemplazar cada punto en el gráfico de dispersión con la clase correspondiente de la instancia (un dígito del 0 al 9), o incluso graficar versiones reducidas de las imágenes de dígitos en sí mismas (si grafica todos los dígitos, la visualización será demasiado desordenada, por lo que debe dibujar una muestra aleatoria o graficar una instancia solo si no se ha graficado otra instancia a una distancia cercana). Debería obtener una visualización con grupos de dígitos bien separados. Intente usar otros algoritmos de reducción de dimensionalidad como PCA, LLE o MDS y compare las visualizaciones resultantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar el conjunto de datos MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "X = mnist[\"data\"]\n",
        "y = mnist[\"target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Dividir el conjunto de datos en un conjunto de entrenamiento y un conjunto de pruebas\n",
        "X_train, X_test = X[:60000], X[60000:]\n",
        "y_train, y_test = y[:60000], y[60000:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar un clasificador Random Forest en el conjunto de entrenamiento\n",
        "import time\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Evaluar el modelo resultante en el conjunto de pruebas\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"Tiempo de entrenamiento del clasificador Random Forest:\", end_time - start_time)\n",
        "print(\"Accuracy del clasificador Random Forest en el conjunto de pruebas:\", accuracy_rf)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "reducir la dimensionalidad del conjunto de datos con PCA y entrenar un nuevo clasificador Random Forest en el conjunto de datos reducido:\n",
        "\n",
        "En este ejemplo, después de dividir el conjunto de datos en un conjunto de entrenamiento y un conjunto de pruebas, estamos reduciendo la dimensionalidad del conjunto de datos utilizando PCA con una relación de varianza explicada del 95%. Para ello, estamos utilizando el método fit_transform() de PCA para ajustar el modelo al conjunto de entrenamiento y transformar los datos.\n",
        "\n",
        "Luego, estamos entrenando un nuevo clasificador Random Forest en el conjunto de datos reducido utilizando la clase RandomForestClassifier() de Scikit-Learn y calculando su tiempo de entrenamiento utilizando la función time.time(). Después, estamos haciendo predicciones en el conjunto de pruebas reducido y evaluando el desempeño del modelo utilizando la función accuracy_score() de Scikit-Learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "# Cargar el conjunto de datos MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "X = mnist[\"data\"]\n",
        "y = mnist[\"target\"]\n",
        "\n",
        "# Dividir el conjunto de datos en un conjunto de entrenamiento y un conjunto de pruebas\n",
        "X_train, X_test = X[:60000], X[60000:]\n",
        "y_train, y_test = y[:60000], y[60000:]\n",
        "\n",
        "# Reducir la dimensionalidad del conjunto de datos con PCA\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_train_reduced = pca.fit_transform(X_train)\n",
        "\n",
        "# Entrenar un nuevo clasificador Random Forest en el conjunto de datos reducido\n",
        "start_time = time.time()\n",
        "rf_clf_reduced = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf_reduced.fit(X_train_reduced, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "# Evaluar el nuevo clasificador en el conjunto de pruebas\n",
        "X_test_reduced = pca.transform(X_test)\n",
        "y_pred_rf_reduced = rf_clf_reduced.predict(X_test_reduced)\n",
        "accuracy_rf_reduced = accuracy_score(y_test, y_pred_rf_reduced)\n",
        "\n",
        "print(\"Tiempo de entrenamiento del clasificador Random Forest reducido:\", end_time - start_time)\n",
        "print(\"Accuracy del clasificador Random Forest reducido en el conjunto de pruebas:\", accuracy_rf_reduced)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "í, entrenar el clasificador Random Forest en el conjunto de datos reducido debería ser mucho más rápido que entrenar el clasificador en el conjunto de datos originales, ya que la cantidad de características se ha reducido considerablemente gracias a PCA.\n",
        "\n",
        "En cuanto al desempeño del clasificador reducido en el conjunto de pruebas, depende de cada conjunto de datos específico, pero en general, se espera que el desempeño sea comparable al del clasificador original o incluso mejor en algunos casos, ya que la reducción de la dimensionalidad puede ayudar a prevenir el overfitting y mejorar la generalización del modelo.\n",
        "\n",
        "En el ejemplo de código que proporcioné anteriormente, estamos imprimiendo el tiempo de entrenamiento y la precisión del clasificador Random Forest original y del clasificador Random Forest reducido en el conjunto de pruebas. Puedes comparar ambos valores y ver si hay una diferencia significativa en el tiempo de entrenamiento y en la precisión del modelo."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " reducir el conjunto de datos MNIST a dos dimensiones utilizando t-SNE y graficar el resultado utilizando un gráfico de dispersión con 10 colores diferentes para representar la clase objetivo de cada imagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el conjunto de datos MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "X = mnist[\"data\"]\n",
        "y = mnist[\"target\"].astype(np.uint8)\n",
        "\n",
        "# Reducir la dimensionalidad del conjunto de datos con t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "X_reduced = tsne.fit_transform(X)\n",
        "\n",
        "# Graficar el resultado\n",
        "plt.figure(figsize=(10, 8))\n",
        "colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
        "for i in range(10):\n",
        "    plt.scatter(X_reduced[y == i, 0], X_reduced[y == i, 1], c=colors[i], label=i, alpha=0.7, s=30)\n",
        "plt.legend()\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "graficar cada punto en el gráfico de dispersión con la clase correspondiente de la instancia (un dígito del 0 al 9) en lugar de usar colores diferentes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el conjunto de datos MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "X = mnist[\"data\"]\n",
        "y = mnist[\"target\"].astype(np.uint8)\n",
        "\n",
        "# Reducir la dimensionalidad del conjunto de datos con t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "X_reduced = tsne.fit_transform(X)\n",
        "\n",
        "# Graficar el resultado\n",
        "plt.figure(figsize=(10, 8))\n",
        "for i in range(X_reduced.shape[0]):\n",
        "    plt.text(X_reduced[i, 0], X_reduced[i, 1], str(y[i]), color=plt.cm.Set1(y[i] / 10.), fontdict={'weight': 'bold', 'size': 9})\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Después, estamos graficando el resultado utilizando la función text() de Matplotlib para agregar el valor de la clase objetivo de cada imagen (del 0 al 9) en lugar de usar colores diferentes. También estamos desactivando los ejes para enfocarnos en la visualización de los puntos.\n",
        "\n",
        "Si en cambio, deseas graficar versiones reducidas de las imágenes de dígitos en sí mismas, puedes usar el siguiente código:\n",
        "\n",
        "En este ejemplo, estamos cargando el conjunto de datos MNIST utilizando la función fetch_openml() de Scikit-Learn. Luego, estamos reduciendo la dimensionalidad del conjunto de datos utilizando t-SNE con dos componentes. Para ello, estamos utilizando el método fit_transform() de t-SNE para ajustar el modelo al conjunto de datos y transformar los datos.\n",
        "\n",
        "Después, estamos graficando el resultado utilizando la función imshow() de Matplotlib para graficar versiones reducidas de las imágenes de d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el conjunto de datos MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "X = mnist[\"data\"]\n",
        "y = mnist[\"target\"].astype(np.uint8)\n",
        "\n",
        "# Reducir la dimensionalidad del conjunto de datos con t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "X_reduced = tsne.fit_transform(X)\n",
        "\n",
        "# Graficar el resultado\n",
        "plt.figure(figsize=(10, 8))\n",
        "img_size = 28\n",
        "for i in range(X_reduced.shape[0]):\n",
        "    plt.imshow(X[i].reshape(img_size, img_size), cmap='binary', extent=(X_reduced[i, 0]-5, X_reduced[i, 0]+5, X_reduced[i, 1]-5, X_reduced[i, 1]+5))\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "quí te muestro cómo utilizar PCA, LLE y MDS para reducir la dimensionalidad del conjunto de datos MNIST y comparar las visualizaciones resultantes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import LocallyLinearEmbedding, MDS\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el conjunto de datos MNIST\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "X = mnist[\"data\"]\n",
        "y = mnist[\"target\"].astype(np.uint8)\n",
        "\n",
        "# Reducción de dimensionalidad con PCA\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_reduced_pca = pca.fit_transform(X)\n",
        "\n",
        "# Reducción de dimensionalidad con LLE\n",
        "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10, random_state=42)\n",
        "X_reduced_lle = lle.fit_transform(X)\n",
        "\n",
        "# Reducción de dimensionalidad con MDS\n",
        "D = pairwise_distances(X, squared=True)\n",
        "mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
        "X_reduced_mds = mds.fit_transform(D)\n",
        "\n",
        "# Graficar los resultados\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.title('PCA')\n",
        "for i in range(10):\n",
        "    plt.scatter(X_reduced_pca[y == i, 0], X_reduced_pca[y == i, 1], alpha=0.5)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "plt.subplot(132)\n",
        "plt.title('LLE')\n",
        "for i in range(10):\n",
        "    plt.scatter(X_reduced_lle[y == i, 0], X_reduced_lle[y == i, 1], alpha=0.5)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "plt.subplot(133)\n",
        "plt.title('MDS')\n",
        "for i in range(10):\n",
        "    plt.scatter(X_reduced_mds[y == i, 0], X_reduced_mds[y == i, 1], alpha=0.5)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uuSAUBYkyO1i"
      },
      "source": [
        "# Preguntas teóricas\n",
        "### Métodos de ensamble\n",
        "\n",
        "1. Si ha entrenado cinco modelos diferentes en los mismos datos de entrenamiento y todos logran una precisión del 95%, ¿existe alguna posibilidad de combinar estos modelos para obtener mejores resultados? Si es así, ¿cómo? Si no, ¿por qué?\n",
        "2. ¿Cuál es la diferencia entre los clasificadores de votación hard y de votación soft?\n",
        "3. ¿Es posible acelerar el entrenamiento de un conjunto de bagging distribuyéndolo en varios servidores? ¿Qué pasa con los conjuntos de pasting, los conjuntos de boosting, los Random Forest o los ensambles Stacking?\n",
        "4. ¿Cuál es el beneficio de la evaluación out-of-bag (OOB)?\n",
        "5. ¿Qué hace que los Extra-Trees sean más aleatorios que los Random Forest regulares? ¿Cómo puede esta aleatoriedad adicional ayudar? ¿Son los Extra-Trees más lentos o más rápidos que los Random Forest regulares?\n",
        "6. Si su conjunto de AdaBoost no se ajusta lo suficientemente bien a los datos de entrenamiento, ¿qué hiperparámetros debe ajustar y cómo?\n",
        "7. Si su conjunto de Gradient Boosting sobreajusta el conjunto de entrenamiento, ¿debería aumentar o disminuir la tasa de aprendizaje?\n",
        "\n",
        "\n",
        "### Reducción dimensional\n",
        "\n",
        "1. What are the main motivations for reducing a dataset’s dimensionality? What are\n",
        "the main drawbacks?\n",
        "2. What is the curse of dimensionality?\n",
        "3. Once a dataset’s dimensionality has been reduced, is it possible to reverse the\n",
        "operation? If so, how? If not, why?\n",
        "4. Can PCA be used to reduce the dimensionality of a highly nonlinear dataset?\n",
        "5. Suppose you perform PCA on a 1,000-dimensional dataset, setting the explained\n",
        "variance ratio to 95%. How many dimensions will the resulting dataset have?\n",
        "6. In what cases would you use vanilla PCA, Incremental PCA, Randomized PCA,\n",
        "or Kernel PCA?\n",
        "7. How can you evaluate the performance of a dimensionality reduction algorithm\n",
        "on your dataset?\n",
        "8. Does it make any sense to chain two different dimensionality reduction algo‐\n",
        "rithms?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Métodos de ensamble\n",
        "\n",
        "    Si ha entrenado cinco modelos diferentes en los mismos datos de entrenamiento y todos logran una precisión del 95%, ¿existe alguna posibilidad de combinar estos modelos para obtener mejores resultados? Si es así, ¿cómo? Si no, ¿por qué?\n",
        "\n",
        "Sí, existe la posibilidad de combinar estos modelos para obtener mejores resultados utilizando métodos de ensamble. Por ejemplo, se podría utilizar un clasificador de votación soft para combinar las predicciones de los cinco modelos, lo que podría aumentar la precisión del modelo combinado. Esto se debe a que los diferentes modelos pueden capturar diferentes aspectos de la relación entre las características y las etiquetas, y al combinar las predicciones de los modelos, se puede reducir el error de generalización.\n",
        "\n",
        "    ¿Cuál es la diferencia entre los clasificadores de votación hard y de votación soft?\n",
        "\n",
        "Un clasificador de votación hard elige la clase con mayor cantidad de votos entre los clasificadores base, mientras que un clasificador de votación soft utiliza las probabilidades de clase estimadas por cada clasificador base para hacer una predicción. En otras palabras, un clasificador de votación hard cuenta los votos, mientras que un clasificador de votación soft toma en cuenta la confianza de cada modelo base.\n",
        "\n",
        "    ¿Es posible acelerar el entrenamiento de un conjunto de bagging distribuyéndolo en varios servidores? ¿Qué pasa con los conjuntos de pasting, los conjuntos de boosting, los Random Forest o los ensambles Stacking?\n",
        "\n",
        "Sí, es posible acelerar el entrenamiento de un conjunto de bagging distribuyéndolo en varios servidores. Cada servidor podría entrenar un modelo base en un subconjunto aleatorio de los datos de entrenamiento y luego combinar los modelos base para crear el modelo final. Esta técnica se conoce como bagging paralelo. Lo mismo se puede aplicar a los conjuntos de pasting, Random Forest y ensambles Stacking. Sin embargo, la aceleración del entrenamiento en el boosting es más difícil debido a que cada modelo base se entrena en función de los errores del modelo anterior, lo que hace que la distribución en múltiples servidores sea complicada.\n",
        "\n",
        "    ¿Cuál es el beneficio de la evaluación out-of-bag (OOB)?\n",
        "\n",
        "La evaluación out-of-bag (OOB) es una técnica utilizada en el bagging que permite evaluar el modelo sin la necesidad de un conjunto de validación. Durante el entrenamiento, se utiliza una muestra aleatoria del conjunto de entrenamiento para cada modelo base, lo que implica que algunas instancias no se utilizan en el entrenamiento de cada modelo. Estas instancias no utilizadas se llaman instancias out-of-bag y se pueden utilizar para evaluar el modelo. La evaluación OOB proporciona una estimación sin sesgo del rendimiento del modelo en datos no vistos.\n",
        "\n",
        "    ¿Qué hace que los Extra-Trees sean más aleatorios que los Random Forest regulares? ¿Cómo puede esta aleatoriedad adicional ayudar? ¿Son los Extra-Trees más lentos o más rápidos que los Random Forest regulares?\n",
        "\n",
        "Los Extra-Trees (Extremely Randomized Trees) son más aleatorios que los Random Forest regulares porque en lugar de seleccionar las características óptimas para dividir cada nodo, utilizan una selección aleatoria de características. Además, las divisiones de nodos se realizan en puntos aleatorios para cada característica. Esta aleatoriedad adicional ayuda a reducir la varianza del modelo, lo que puede mejorar su rendimiento en datos no vistos. Los Extra-Trees son generalmente más rápidos que los Random Forest regulares, ya que la selección aleatoria de características reduce el tiempo necesario para encontrar la mejor característica para cada nodo.\n",
        "\n",
        "    Si su conjunto de AdaBoost no se ajusta lo suficientemente bien a los datos de entrenamiento, ¿qué hiperparámetros debe ajustar y cómo?\n",
        "\n",
        "Si el conjunto de AdaBoost no se ajusta lo suficientemente bien a los datos de entrenamiento, se pueden ajustar varios hiperparámetros, como la tasa de aprendizaje (learning rate) y el número de estimadores (n_estimators).\n",
        "\n",
        "Aumentar la tasa de aprendizaje (learning rate) puede ayudar a hacer que el conjunto sea más sensible a los errores del modelo anterior y, por lo tanto, a reducir el sesgo. Aumentar el número de estimadores también puede mejorar el rendimiento del conjunto, permitiendo que el modelo tenga más oportunidades de ajustarse a los datos. También se pueden ajustar otros hiperparámetros, como el criterio de división de nodos (splitter) y la profundidad máxima del árbol (max_depth), para mejorar el rendimiento.\n",
        "\n",
        "    Si su conjunto de Gradient Boosting sobreajusta el conjunto de entrenamiento, ¿debería aumentar o disminuir la tasa de aprendizaje?\n",
        "\n",
        "Si el conjunto de Gradient Boosting sobreajusta el conjunto de entrenamiento, debería disminuir la tasa de aprendizaje para reducir la velocidad a la que se ajusta el modelo a los errores del modelo anterior. Al disminuir la tasa de aprendizaje, el modelo tendrá menos oportunidades de sobreajustar el conjunto de entrenamiento y, por lo tanto, debería generalizar mejor a los datos no vistos. También se pueden considerar otras técnicas para reducir el sobreajuste, como reducir la profundidad de los árboles o utilizar una muestra aleatoria de las características en cada iteración.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eO5sI21nzyxi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
