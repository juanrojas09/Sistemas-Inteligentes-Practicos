{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [714, 891]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/juan-pablo/Escritorio/Sist inteligente/PARCIAL 1/tphelper.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan-pablo/Escritorio/Sist%20inteligente/PARCIAL%201/tphelper.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mdropna()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan-pablo/Escritorio/Sist%20inteligente/PARCIAL%201/tphelper.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Dividir en conjunto de entrenamiento y prueba\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/juan-pablo/Escritorio/Sist%20inteligente/PARCIAL%201/tphelper.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, Y, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan-pablo/Escritorio/Sist%20inteligente/PARCIAL%201/tphelper.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Definir los modelos a evaluar\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/juan-pablo/Escritorio/Sist%20inteligente/PARCIAL%201/tphelper.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m log_clf \u001b[39m=\u001b[39m LogisticRegression(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2559\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[1;32m   2561\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[1;32m   2562\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[1;32m   2564\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[0;32m--> 443\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[1;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [714, 891]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, accuracy_score\n",
    "\n",
    "url = 'https://gitlab.com/francisco.arduh/datasets/-/raw/main/Titanic-Dataset.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "#En la variable de características borro las columnas irrelevantes\n",
    "X=data.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "Y=data['Survived']\n",
    "\n",
    "# Codificar variables categóricas\n",
    "le = LabelEncoder()\n",
    "X['Sex'] = le.fit_transform(X['Sex'])\n",
    "X['Embarked'] = le.fit_transform(X['Embarked'].fillna('S'))\n",
    "\n",
    "# Eliminar filas con datos faltantes\n",
    "X = X.dropna()\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir los modelos a evaluar\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Crear un pipeline para cada modelo\n",
    "log_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    log_clf\n",
    ")\n",
    "forest_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    forest_clf\n",
    ")\n",
    "\n",
    "# Entrenar y evaluar los modelos con validación cruzada\n",
    "log_auc_scores = cross_val_score(log_pipeline, x_train, y_train, cv=3, scoring='roc_auc')\n",
    "forest_auc_scores = cross_val_score(forest_pipeline, x_train, y_train, cv=3, scoring='roc_auc')\n",
    "\n",
    "# Elegir el modelo con mejor AUC-ROC\n",
    "if log_auc_scores.mean() > forest_auc_scores.mean():\n",
    "    best_model = log_pipeline\n",
    "    print(\"Mejor modelo: Logistic Regression\")\n",
    "else:\n",
    "    best_model = forest_pipeline\n",
    "    print(\"Mejor modelo: Random Forest Classifier\")\n",
    "\n",
    "# Entrenar el mejor modelo con todos los datos de entrenamiento\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "# Predecir las clases y los puntajes para la región de prueba\n",
    "y_pred = best_model.predict(x_test)\n",
    "y_scores = best_model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Calcular y mostrar las métricas\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
